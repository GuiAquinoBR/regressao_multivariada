---
title: "Trilha 5 - Tarefa - RMarkdown - Big Data Analytics Análise Estatística"
author: "Silva, Guilherme Aquino"
date: "2023-03-17"
output: word_document
---

# Big Data Analytics: Análise Estatística

## Neste exercício vamos fazer uma análise de regressão multivariada com a mesma base de dados autos.csv para tentar prever o preço de carro a partir das seguintes variáveis: potência (horsepower), comprimento (length), tamanho do motor (engine.size), consumo na cidade (city.mpg).

```{r}
library(GGally)
library(ggplot2)
library(MASS)
library(dplyr)
```

```{r}
autos <- read.csv('C:/Users/guilh/OneDrive/Área de Trabalho/Mackenzie/Modulo 3 - Big Data Analytics - Análise Estatística/Datasets do módulo/autos.csv', 
                  sep = ';', dec = ',')
```


### *Análise exploratória:*

```{r}
autos2 <- autos[, c('price', 'horsepower', 'length', 'engine.size', 'city.mpg')]

head(autos2) # Começo dos dados
```

```{r}
tail(autos2) # Final dos dados
```

```{r}
summary(autos2) # Sumário dos dados
```

```{r}
dim(autos2) # Dimensão dos dados
```
```{r}
str(autos2) # Estrutura dos dados
```

```{r}
ggplot(autos2) +
  geom_point(aes(price, horsepower), color = 'red') +
  labs(title = 'Figura 1: Preço dos Automóveis x Potência dos Automóveis', x = 'Preço', y = 'Potência', caption = 'Fonte: Elaborada pelo autor.')
```


*Na Figura 1 apresentada acima, vemos que, conforme a potência do automóvel aumenta, o seu preço também aumenta.*


```{r}
ggplot(autos2) +
  geom_point(aes(price, length), color = 'red') +
  labs(title = 'Figura 2: Preço dos Automóveis x Comprimento dos Automóveis', x = 'Preço', y = 'Comprimento', caption = 'Fonte: Elaborada pelo autor.')
```


*Assim como na Figura 1, a Figura 2 apresenta o mesmo padrão de aumento: quanto maior o comprimento do automóvel, maior será o preço, porém os dados apresentam uma distribuição diferente, não linear, com maior concentração no valor da variável Preço em até 20000.*


```{r}
ggplot(autos2) +
  geom_point(aes(price, engine.size), color = 'red') +
  labs(title = 'Figura 3: Preço dos Automóveis x Tamanho do Motor', x = 'Preço', y = 'Tamanho do Motor', caption = 'Fonte: Elaborada pelo autor.')
```


*O gráfico de dispersão apresentado na Figura 3, mostra uma forte relação crescente aproximadamente linear entre o preço e o tamanho do motor.*


```{r}
ggplot(autos2) +
  geom_point(aes(price, city.mpg), color = 'red') +
  labs(title = 'Figura 4: Preço dos Automóveis x Milhas por Galão (Cidade)', x = 'Preço', y = 'Milhas por Galão', caption = 'Fonte: Elaborada pelo autor.')
```


*No gráfico da Figura 4, vemos uma distribuição decrescente, onde quanto maior o preço do automóvel, menor é o seu consumo dentro da cidade.*


```{r}
cor(autos2) # Correlação dos dados
```

```{r}
ggcorr(autos2, palette = 'RdYlGn', name = bquote(rho), label = T, label_color = 'black') +
  labs(title = 'Figura 5: Gráfico de correlação entre as variáveis',caption = 'Fonte: Elaborado pelo autor.')
```


*Observe que o gráfico de correlação entre as variáveis que estamos trabalhando (Figura 5), confirma a informação vista na Figura 4, onde a variável que menos tem impacto nas demais variáveis é o consumo dos automóveis (city.mpg).*


### *Ajustando um modelo de regressão linear ao dados:*
```{r}
modelo <- lm(price ~ horsepower + length + engine.size + city.mpg, data = autos2)

summary(modelo)
```


*Os parâmetros horsepower, length e engine.size possuem um valor p menor que 5%, indicando a escolha da hipótese alternativa, onde a potência do motor, o comprimento e o tamanho do motor está ligado ao aumento do preço dos automóveis. Por outro lado, o parâmetro city.mpg não apresenta significância estatística podendo, assim, ser removido do modelo.*


```{r}
modelo2 <- lm(price ~ . - city.mpg, autos2) # Removendo o parâmetro city.mpg do modelo

summary(modelo2)
```


*Após a atualização do modelo, vemos que não houve uma mudança significativa nos valores R-quadrado e R-quadrado ajustado, ambos indicando que o modelo explica aproximadamente 81% dos dados, o mesmo percentual apresentado no modelo anterior.*


### *Gráfico dos resíduos:*
```{r}
par(mfrow = c(2,2))
plot(modelo2)
```


*O modelo atual não atende as premissas estatísticas do método dos mínimos quadrados ordinários - OLS. Os resíduos do modelo não tem um comportamento próximo do que se espera, isto é, há uma ocilação na solução apresentada e, de acordo com a dispersão desses resíduos, indica não ser uma regressão linear. Já o gráfico Normal Q-Q não segue uma distribuição normal dentro do que seria aceitável. Há uma discrepância na área superior e inferior do gráfico, sendo necessário a aplicação de alguma técnica matemática para normalizar os dados.*


### *Transformação da Variável Resposta:*


**Teste de Normalidade de Shapiro-Wilk:**
```{r}
shapiro.test(residuals(modelo2))
```


*Observamos, pelo Teste de Normalidade de Shapiro-Wilk, que a hipótese nula deve ser rejeitada, já que obtivemos um p-value de 5.149e-05*


```{r}
df_residuos <- data.frame(Residuos = residuals(modelo2), 
                          Ajustados = fitted(modelo2))

ggplot(df_residuos) +
  geom_histogram(aes(Residuos), fill = 'lightblue') +
  labs(title = 'Figura 6: Histograma dos Resíduos', x = 'Resíduos', caption = 'Fonte: Elaborado pelo autor.')
```


*Na Figura 6, observamos que os resíduos aparentam ter uma distribuição multimodal.*


```{r}
par(mfrow = c(1,1))
boxcox(modelo2, data = autos2, eps = 0.001)
mtext('Fonte: Elaborada pelo autor.', xpd = NA, cex = 0.7, side = 1, line = 3.8, adj = 1)
```


**Técnica matemática Box-Cox:**
```{r}
bx <- boxcox(modelo2, data = autos2, eps = 0.001, plotit = F)

bx_df <- data.frame(x = bx$x, y = bx$y)

bx_df2 <- bx_df[with(bx_df, order(-bx_df$y)),]

bx_df2[1,]
```


*Pelo gráfico verificamos que o intervalo de confiança é de 95% com valor de lambda = -0.4.*


```{r}
lambda <- round(bx_df2[1,"x"],3)

resposta_transf <- mutate(autos2, price_transf = (price^lambda - 1) / lambda) # Inserindo a nova variável 
```


```{r}
modelo3 <- lm(price_transf ~ horsepower + length + engine.size, data = resposta_transf)

summary(modelo3)
```


*Examinando o sumário do novo modelo ajustado após a transformação da variável resposta, nota-se um aumento no valor do R-quadrado de 81% para 83%.*


```{r}
par(mfrow = c(2,2))
plot(modelo3)
```


*Avaliando os gráficos diagnósticos, vemos uma melhora nas distribuições dos resíduos apresentando ser aleatórios e mais próximos de uma normalidade.*


```{r}
df_residuos2 <- data.frame(Residuos = residuals(modelo3), 
                           Ajustados = fitted(modelo3))

ggplot(df_residuos2) +
  geom_histogram(aes(Residuos), fill = 'lightblue') +
  labs(title = 'Figura 7: Histograma dos Resíduos', x = 'Resíduos', caption = 'Fonte: Elaborado pelo autor.')
```


**Teste de Normalidade de Shapiro-Wilk:**
```{r}
shapiro.test(residuals(modelo3)) 
```


*De acordo com o teste de Shapiro-Wilk o p-value cai na região de aceitação da hipótese nula, indicando que a transformação surtiu efeito.*


### *Transformação da Variável Explicativa:*

```{r}
# Realizando a transformação aplicando a função raiz quadrada e gerando novas colunas
explica_transf <- mutate(resposta_transf, 
                         horsepower_transf = sqrt(horsepower), 
                         length_transf = sqrt(length),
                         engine.size_transf = sqrt(engine.size))
```


```{r}
modelo4 <- lm(price_transf ~ horsepower_transf + length_transf + engine.size_transf, explica_transf)

summary(modelo4)
```


```{r}
par(mfrow = c(2,2))
plot(modelo4)
```


**Teste de Normalidade de Shapiro-Wilk:**
```{r}
shapiro.test(residuals(modelo4))
```

*O modelo final ajustado aos dados após a transformação das variáveis explicativas, apresentam resíduos em simetria, com R-quadrado ajustado de 84% (maior que os últimos três modelos anteriores). A análise dos resíduos mostrados nos gráficos diagnósticos, indica a aleatoriedade dos resíduos e um ajuste mais próximo da normalidade que o modelo anterior, assim como o Teste de Normalidade de Shapiro-Wilk, cujo P-value é 0.2323.*


### *Avaliando a habilidade preditora do nosso modelo:*


```{r}
# Mantendo as colunas necessárias
autos3 <- subset(explica_transf, select = c(price_transf, horsepower_transf, length_transf, engine.size_transf))

set.seed(3845)

# Separando os dados em dados de treino e teste
treino <- sample_frac(autos3, 0.7)
sid <- as.numeric(rownames(treino))
teste <- autos3[-sid,]
```

```{r}
fit <- predict(modelo4, newdata = teste, type = 'response')

diferenca <- fit - teste$price_transf

(rmse <- sqrt(mean(diferenca^2)))
```


*Vemos um exelente resultado de teste de predição do nosso modelo estando muito próximo a zero.*


### *Análise:*


*O modelo linear final apresentado, sugere que um aumento de 1% no preço do automóvel está associado com um aumento de 0.0026746 de sua potência, 0.0095234 de aumento de seu comprimento e 0.0015772 de aumento do tamanho de seu motor.*

*Em conjunto, as variáveis preditoras respondem por 84% da variância no preço do automóvel, sendo este o mesmo percentual adquirido pela valor do R-quadrado ajustado.*